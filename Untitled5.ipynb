{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi4mFYMRqWCw",
        "outputId": "04f531f7-71d3-451e-9584-1b620476cca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WJvAbC3EC20",
        "outputId": "ac4a8e16-4d2c-455f-c4ed-ecc9c95a584f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "|       1|01/01/2020 12:28:...| 01/01/2020 12:33:...|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|       11.27|                 2.5|\n",
            "|       1|01/01/2020 12:35:...| 01/01/2020 12:43:...|              1|          1.2|         1|                 N|         239|         238|           1|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.3|                 2.5|\n",
            "|       1|01/01/2020 12:47:...| 01/01/2020 12:53:...|              1|          0.6|         1|                 N|         238|         238|           1|        6.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        10.8|                 2.5|\n",
            "|       1|01/01/2020 12:55:...| 01/01/2020 01:00:...|              1|          0.8|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|         0.0|                  0.3|        8.16|                 0.0|\n",
            "|       2|01/01/2020 12:01:...| 01/01/2020 12:04:...|              1|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- VendorID: string (nullable = true)\n",
            " |-- tpep_pickup_datetime: string (nullable = true)\n",
            " |-- tpep_dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: integer (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- RatecodeID: integer (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: integer (nullable = true)\n",
            " |-- DOLocationID: integer (nullable = true)\n",
            " |-- payment_type: integer (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- improvement_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- congestion_surcharge: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Trips_Analysis\").getOrCreate()\n",
        "\n",
        "# You can read all CSVs at once using a wildcard\n",
        "\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/csv_files/Taxi Datset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "raw_df = spark.read.csv(\"/content/drive/MyDrive/csv_files/Taxi Datset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df.show(5)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LMm8Ry2oxHpF",
        "outputId": "5724c6f2-4267-4be1-b425-f8fbdfa9a31d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' file = \"TaxiDataset.csv\"\\ndata_nodes = [\"DataNode_1\", \"DataNode_2\", \"DataNode_3\",\\n              \"DataNode_4\", \"DataNode_5\", \"DataNode_6\"]\\n\\nreplication_factor = 3\\n\\n# pick 3 unique nodes:\\nimport random\\nreplicas = random.sample(data_nodes, replication_factor)\\n\\nprint(\"HDFS placement:\")\\nprint(f\"{file} -> {replicas}\") '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "''' file = \"TaxiDataset.csv\"\n",
        "data_nodes = [\"DataNode_1\", \"DataNode_2\", \"DataNode_3\",\n",
        "              \"DataNode_4\", \"DataNode_5\", \"DataNode_6\"]\n",
        "\n",
        "replication_factor = 3\n",
        "\n",
        "# pick 3 unique nodes:\n",
        "import random\n",
        "replicas = random.sample(data_nodes, replication_factor)\n",
        "\n",
        "print(\"HDFS placement:\")\n",
        "print(f\"{file} -> {replicas}\") '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Oj14Rrqbs-jt"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import sum as spark_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "At_YO71LEX0x"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"pickup_time\", to_timestamp(col(\"tpep_pickup_datetime\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
        "\n",
        "df = df.withColumn(\"dropoff_time\", to_timestamp(col(\"tpep_dropoff_datetime\"), \"MM/dd/yyyy hh:mm:ss a\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OjqMnimFo6S",
        "outputId": "d3b32ff2-0735-4983-f757-d7a91de1660d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+-------------------+\n",
            "|tpep_pickup_datetime  |pickup_time        |\n",
            "+----------------------+-------------------+\n",
            "|01/01/2020 12:28:15 AM|2020-01-01 00:28:15|\n",
            "|01/01/2020 12:35:39 AM|2020-01-01 00:35:39|\n",
            "|01/01/2020 12:47:41 AM|2020-01-01 00:47:41|\n",
            "|01/01/2020 12:55:23 AM|2020-01-01 00:55:23|\n",
            "|01/01/2020 12:01:58 AM|2020-01-01 00:01:58|\n",
            "|01/01/2020 12:09:44 AM|2020-01-01 00:09:44|\n",
            "|01/01/2020 12:39:25 AM|2020-01-01 00:39:25|\n",
            "|12/18/2019 03:27:49 PM|2019-12-18 15:27:49|\n",
            "|12/18/2019 03:30:35 PM|2019-12-18 15:30:35|\n",
            "|01/01/2020 12:29:01 AM|2020-01-01 00:29:01|\n",
            "+----------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"tpep_pickup_datetime\", \"pickup_time\").show(10, truncate=False) #shows the full content of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "TPW_P71vFp9O"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"year\", year(\"pickup_time\"))\n",
        "df = df.filter(col(\"year\").isin(2016, 2017, 2018, 2019, 2020))\n",
        "\n",
        "df = df.withColumn(\"trip_duration_minutes\", (col(\"dropoff_time\").cast(\"long\") - col(\"pickup_time\").cast(\"long\")) / 60)\n",
        "\n",
        "df = df.withColumn(\"total_fare\", col(\"fare_amount\") + col(\"tip_amount\"))\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"extra_charges\",\n",
        "    col(\"tolls_amount\") +\n",
        "    col(\"congestion_surcharge\") +\n",
        "    col(\"mta_tax\") +\n",
        "    col(\"extra\") +\n",
        "    col(\"improvement_surcharge\")\n",
        ")\n",
        "\n",
        "df = df.withColumn(\"month\", month(\"pickup_time\"))\n",
        "df = df.withColumn(\"day_of_week\", dayofweek(\"pickup_time\"))\n",
        "df = df.withColumn(\"hour\", hour(\"pickup_time\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emOd7Z4pyYmJ",
        "outputId": "8bb4cde2-4331-4970-e1fa-31d57ccd5ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+-------------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|        pickup_time|       dropoff_time|year|trip_duration_minutes|total_fare|extra_charges|month|day_of_week|hour|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+-------------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|       1|01/01/2020 12:28:...| 01/01/2020 12:33:...|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|       11.27|                 2.5|2020-01-01 00:28:15|2020-01-01 00:33:03|2020|                  4.8|      7.47|          6.3|    1|          4|   0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-------------------+-------------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2d3KSZa6dbg",
        "outputId": "c93f6f5c-cfc8-49b8-dcfa-bbc234cac5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+---------------------+------------------+-------------+------------------+------------------+------------+------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|          VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|   passenger_count|trip_distance|        RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|      payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|pickup_time|dropoff_time|year|trip_duration_minutes|total_fare|extra_charges|month|day_of_week|hour|\n",
            "+------------------+--------------------+---------------------+------------------+-------------+------------------+------------------+------------+------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|0.7673999685480811|                 0.0|                  0.0|0.7673999685480811|          0.0|0.7673999685480811|0.7673999685480811|         0.0|         0.0|0.7673999685480811|        0.0|  0.0|    0.0|       0.0|         0.0|                  0.0|         0.0|                 0.0|        0.0|         0.0| 0.0|                  0.0|       0.0|          0.0|  0.0|        0.0| 0.0|\n",
            "+------------------+--------------------+---------------------+------------------+-------------+------------------+------------------+------------+------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_rows = df.count()\n",
        "\n",
        "null_percent = df.select([\n",
        "    (spark_sum(col(c).isNull().cast(\"int\")) / total_rows * 100).alias(c)\n",
        "    for c in df.columns\n",
        "])\n",
        "null_percent.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BtLcLhKt6hBY",
        "outputId": "780c8c29-f5fe-4a05-fd96-a2019746aadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|VendorID|passenger_count|trip_distance|PULocationID|DOLocationID|payment_type|total_amount|year|trip_duration_minutes|total_fare|extra_charges|month|day_of_week|hour|\n",
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|       1|              1|          1.2|         238|         239|           1|       11.27|2020|                  4.8|      7.47|          6.3|    1|          4|   0|\n",
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dropped_columns = [\n",
        "    \"RatecodeID\",             # not needed\n",
        "    \"store_and_fwd_flag\",     # not needed\n",
        "    \"tpep_pickup_datetime\",   # original string datetime, replaced by trip_duration_minutes\n",
        "    \"tpep_dropoff_datetime\",  # original string datetime, replaced by trip_duration_minutes\n",
        "    \"pickup_time\",            # replaced by trip_duration_minutes, year, month, day_of_week\n",
        "    \"dropoff_time\",           # replaced by trip_duration_minutes, year, month, day_of_week\n",
        "    \"fare_amount\",            # merged into total_fare\n",
        "    \"tip_amount\",             # merged into total_fare\n",
        "    \"tolls_amount\",           # merged into extra_charges\n",
        "    \"congestion_surcharge\",   # merged into extra_charges\n",
        "    \"mta_tax\",                # merged into extra_charges\n",
        "    \"extra\",                  # merged into extra_charges\n",
        "    \"improvement_surcharge\"   # merged into extra_charges\n",
        "]\n",
        "df = df.drop(*dropped_columns)\n",
        "df.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m1CsXCE9cpXM"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [\"trip_distance\", \"total_fare\", \"extra_charges\",\"trip_duration_minutes\", \"passenger_count\"] #[4] new\n",
        "\n",
        "#removing outliers\n",
        "for c in numeric_cols:\n",
        "    q1, q3 = df.approxQuantile(c, [0.25, 0.75], 0.01)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    df = df.filter((col(c) >= lower_bound) & (col(c) <= upper_bound))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BxyOhC6bee2I"
      },
      "outputs": [],
      "source": [
        "df = df.filter(col(\"trip_duration_minutes\").isNotNull() & (col(\"trip_duration_minutes\") > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "Loas9fJiefrU"
      },
      "outputs": [],
      "source": [
        "#handling nulls in the numerical columns.\n",
        "for c in numeric_cols:\n",
        "    median_value = df.approxQuantile(c, [0.5], 0.01)[0]\n",
        "    df = df.fillna({c: median_value})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dmRUqLm0hNHM"
      },
      "outputs": [],
      "source": [
        "#handling nulls in the categorical columns.\n",
        "categorical_cols = [\"PULocationID\", \"DOLocationID\", \"payment_type\", \"VendorID\"] # [2], [3] new\n",
        "\n",
        "for c in categorical_cols:\n",
        "    mode_value = df.groupBy(c).count().orderBy(col(\"count\").desc()).first()[0]\n",
        "    df = df.fillna({c: mode_value})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf5LigBa-kLc",
        "outputId": "723a0455-f838-42be-9623-9749d023d89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|VendorID|passenger_count|trip_distance|PULocationID|DOLocationID|payment_type|total_amount|year|trip_duration_minutes|total_fare|extra_charges|month|day_of_week|hour|\n",
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "|     0.0|            0.0|          0.0|         0.0|         0.0|         0.0|         0.0| 0.0|                  0.0|       0.0|          0.0|  0.0|        0.0| 0.0|\n",
            "+--------+---------------+-------------+------------+------------+------------+------------+----+---------------------+----------+-------------+-----+-----------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_rows_after = df.count() #new\n",
        "null_percent_after = df.select([\n",
        "    (spark_sum(col(c).isNull().cast(\"int\")) / total_rows * 100).alias(c)\n",
        "    for c in df.columns\n",
        "])\n",
        "null_percent_after.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTja8oC-sfKz",
        "outputId": "5682d7a0-967a-4486-ac77-0a6216dfeb00",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|PULocationID|total_trips|\n",
            "+------------+-----------+\n",
            "|         237|     464327|\n",
            "|         161|     432344|\n",
            "|         236|     428958|\n",
            "|         162|     361393|\n",
            "|         186|     349178|\n",
            "|         230|     334989|\n",
            "|         142|     306790|\n",
            "|         234|     300971|\n",
            "|         170|     300843|\n",
            "|          48|     294838|\n",
            "+------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+----+--------------+\n",
            "|year|avg_total_fare|\n",
            "+----+--------------+\n",
            "|2019|          9.72|\n",
            "|2020|         10.54|\n",
            "+----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Spark SQL Aggregations\n",
        "df.createOrReplaceTempView(\"trips\")\n",
        "\n",
        "spark.sql(\"SELECT PULocationID, COUNT(*) AS total_trips FROM trips GROUP BY PULocationID ORDER BY total_trips DESC\").show(10)\n",
        "\n",
        "spark.sql(\"SELECT year, ROUND(AVG(total_fare),2) AS avg_total_fare FROM trips GROUP BY year ORDER BY year\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictive Analytics\n",
        "# create the df containing the features & actual data (lable) for model training\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"PULocationID\",\"DOLocationID\",\"trip_distance\",\"trip_duration_minutes\",\"total_fare\",\"extra_charges\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "ML_df = assembler.transform(df)\\\n",
        "    .select(\"features\", col(\"total_amount\").alias(\"label\"))\n",
        "\n",
        "train, test = ML_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "train.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG_PdWWL2MwK",
        "outputId": "a575d538-7c98-4cbf-8e84-2b9ce59f9ef8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[1.0,1.0,0.0,0.03...|  3.3|\n",
            "|[1.0,1.0,0.0,0.05...| 21.3|\n",
            "|[1.0,1.0,0.0,0.21...| 20.3|\n",
            "|[1.0,1.0,0.0,0.28...| 12.3|\n",
            "|[1.0,1.0,0.0,0.31...| 10.3|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a regression model , training it and predecting using the df created above\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "reg = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "Reg_model = reg.fit(train)\n",
        "prediction = Reg_model.transform(test)\n",
        "\n",
        "prediction.show(10)"
      ],
      "metadata": {
        "id": "ncPAg5YK8_jW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "\n",
        "rmse = evaluator.evaluate(prediction)\n",
        "print(\"RMSE =\", rmse)\n"
      ],
      "metadata": {
        "id": "tk1SK3egJ_st",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of Regression model\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"r2\"\n",
        ")\n",
        "\n",
        "r2 = evaluator.evaluate(prediction)\n",
        "print(f\"R2 score: {r2}\")"
      ],
      "metadata": {
        "id": "ArHyzKEnOnbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4iBHOOd6lAP"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"passenger_count\") \\\n",
        "  .agg(\n",
        "      avg(\"total_fare\").alias(\"avg_fare\"),\n",
        "      avg(\"total_amount\").alias(\"avg_total\")\n",
        "  ).orderBy(\"passenger_count\") \\\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h87HFNPy7GsL"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"VendorID\") \\\n",
        "  .agg(\n",
        "      avg(\"total_fare\").alias(\"avg_fare\"),\n",
        "      avg(\"total_amount\").alias(\"avg_total\")\n",
        "  ) \\\n",
        "  .orderBy(\"VendorID\") \\\n",
        "  .show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKb9NWHr9Tjt"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"payment_type\") \\\n",
        "  .agg(\n",
        "      avg(\"total_fare\").alias(\"avg_fare\"),\n",
        "      avg(\"total_amount\").alias(\"avg_total\")\n",
        "  ) \\\n",
        "  .orderBy(\"payment_type\") \\\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUFXPPKh9935"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"hour\").count().orderBy(\"hour\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDPV2hXW_5SN"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"day_of_week\").count().orderBy(\"day_of_week\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oukqk-mSABxL"
      },
      "outputs": [],
      "source": [
        "df.groupBy(\"month\").count().orderBy(\"month\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPWUj3KpAEHV"
      },
      "outputs": [],
      "source": [
        "df_bins = df.withColumn(\n",
        "    \"duration_bin\",\n",
        "    when(col(\"trip_duration_minutes\") < 5, \"<5 min\")\n",
        "    .when(col(\"trip_duration_minutes\") < 10, \"5-10 min\")\n",
        "    .when(col(\"trip_duration_minutes\") < 20, \"10-20 min\")\n",
        "    .otherwise(\">20 min\")\n",
        ")\n",
        "df_bins.groupBy(\"duration_bin\") \\\n",
        "    .agg(\n",
        "        avg(col(\"trip_distance\") / col(\"trip_duration_minutes\")).alias(\"avg_distance_per_minute\")\n",
        "    ) \\\n",
        "    .orderBy(\"duration_bin\") \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqSjPB7QFYEz"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max, min\n",
        "\n",
        "df.groupBy(\"payment_type\") \\\n",
        "  .agg(\n",
        "      max(\"total_fare\").alias(\"max_fare\"),\n",
        "      min(\"total_fare\").alias(\"min_fare\")\n",
        "  ) \\\n",
        "  .orderBy(\"payment_type\") \\\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L6mYds-IiZZ"
      },
      "outputs": [],
      "source": [
        "df.select(\n",
        "    max(\"trip_distance\").alias(\"max_distance\"),\n",
        "    min(\"trip_distance\").alias(\"min_distance\")\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmr_9cODK4Hw"
      },
      "outputs": [],
      "source": [
        "df_filtered = df.filter(col(\"trip_distance\") >= 0)\n",
        "\n",
        "df_filtered.select(\n",
        "    max(\"trip_distance\").alias(\"max_distance\"),\n",
        "    min(\"trip_distance\").alias(\"min_distance\")\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_pd = df.toPandas(\"trips\").copy()\n",
        "plt.figure(df_pd).sort_values(\"avg_fare\").plot(kind=\"bar\", x=\"VendorID\", y=\"avg_fare\", edgecolor=\"black\")\n",
        "plt.title(\"Average Fare by Vendor (from JSON docs)\")\n",
        "plt.xlabel(\"Vendor\"); plt.ylabel(\"Average Fare\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xomdBj4KSObx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}